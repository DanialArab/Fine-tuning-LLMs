# Fine-tuning LLMs

This repo documents my understanding of fine-tuning LLMs, which is mostly based on chapters 1, 2, and 6 of the book **<a href="https://www.manning.com/books/build-a-large-language-model-from-scratch">Build a Large Language Model (From Scratch)</a>** by Sebastian Raschka. 

# Table of content

1. [Intro](#1)
2. [Data preparation to make them LLM-friendly](#2)
3. [Re-architecting the LLM](#3)
4. [Fine-tuning LLM](#4)
5. [Model evaluation](#10)
6. [Model deployment](#6)
  
<a name="1"></a>
## Intro
Here, I will focus on **classification fine-tunning** as a technique to get LLM working as an alternative to traditional classifiers. To fine-tune LLM, we need a pipeline to perform:
- Data preparation to make them LLM-friendly
- Re-architecting the LLM
- Fine-tuning LLM
- Model evaluation
- Model deployment

<a name="1"></a>
## Intro
